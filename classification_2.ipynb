{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification. Linear models and KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.metrics import plot_confusion_matrix, accuracy_score, roc_auc_score\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Porto Seguro’s Safe Driver Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's build a model that predicts the probability that a driver will initiate an auto insurance claim in the next year.\n",
    "Read the detailed description and download the dataset https://www.kaggle.com/c/porto-seguro-safe-driver-prediction/data. Put the data into *./data/porto/*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"./data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "insurance_data = pd.read_csv(os.path.join(PATH, 'porto', 'train.csv')).set_index('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>ps_ind_01</th>\n",
       "      <th>ps_ind_02_cat</th>\n",
       "      <th>ps_ind_03</th>\n",
       "      <th>ps_ind_04_cat</th>\n",
       "      <th>ps_ind_05_cat</th>\n",
       "      <th>ps_ind_06_bin</th>\n",
       "      <th>ps_ind_07_bin</th>\n",
       "      <th>ps_ind_08_bin</th>\n",
       "      <th>ps_ind_09_bin</th>\n",
       "      <th>...</th>\n",
       "      <th>ps_calc_11</th>\n",
       "      <th>ps_calc_12</th>\n",
       "      <th>ps_calc_13</th>\n",
       "      <th>ps_calc_14</th>\n",
       "      <th>ps_calc_15_bin</th>\n",
       "      <th>ps_calc_16_bin</th>\n",
       "      <th>ps_calc_17_bin</th>\n",
       "      <th>ps_calc_18_bin</th>\n",
       "      <th>ps_calc_19_bin</th>\n",
       "      <th>ps_calc_20_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.036448</td>\n",
       "      <td>1.900378</td>\n",
       "      <td>1.358943</td>\n",
       "      <td>4.423318</td>\n",
       "      <td>0.416794</td>\n",
       "      <td>0.405188</td>\n",
       "      <td>0.393742</td>\n",
       "      <td>0.257033</td>\n",
       "      <td>0.163921</td>\n",
       "      <td>0.185304</td>\n",
       "      <td>...</td>\n",
       "      <td>5.441382</td>\n",
       "      <td>1.441918</td>\n",
       "      <td>2.872288</td>\n",
       "      <td>7.539026</td>\n",
       "      <td>0.122427</td>\n",
       "      <td>0.627840</td>\n",
       "      <td>0.554182</td>\n",
       "      <td>0.287182</td>\n",
       "      <td>0.349024</td>\n",
       "      <td>0.153318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.187401</td>\n",
       "      <td>1.983789</td>\n",
       "      <td>0.664594</td>\n",
       "      <td>2.699902</td>\n",
       "      <td>0.493311</td>\n",
       "      <td>1.350642</td>\n",
       "      <td>0.488579</td>\n",
       "      <td>0.436998</td>\n",
       "      <td>0.370205</td>\n",
       "      <td>0.388544</td>\n",
       "      <td>...</td>\n",
       "      <td>2.332871</td>\n",
       "      <td>1.202963</td>\n",
       "      <td>1.694887</td>\n",
       "      <td>2.746652</td>\n",
       "      <td>0.327779</td>\n",
       "      <td>0.483381</td>\n",
       "      <td>0.497056</td>\n",
       "      <td>0.452447</td>\n",
       "      <td>0.476662</td>\n",
       "      <td>0.360295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              target      ps_ind_01  ps_ind_02_cat      ps_ind_03  \\\n",
       "count  595212.000000  595212.000000  595212.000000  595212.000000   \n",
       "mean        0.036448       1.900378       1.358943       4.423318   \n",
       "std         0.187401       1.983789       0.664594       2.699902   \n",
       "min         0.000000       0.000000      -1.000000       0.000000   \n",
       "25%         0.000000       0.000000       1.000000       2.000000   \n",
       "50%         0.000000       1.000000       1.000000       4.000000   \n",
       "75%         0.000000       3.000000       2.000000       6.000000   \n",
       "max         1.000000       7.000000       4.000000      11.000000   \n",
       "\n",
       "       ps_ind_04_cat  ps_ind_05_cat  ps_ind_06_bin  ps_ind_07_bin  \\\n",
       "count  595212.000000  595212.000000  595212.000000  595212.000000   \n",
       "mean        0.416794       0.405188       0.393742       0.257033   \n",
       "std         0.493311       1.350642       0.488579       0.436998   \n",
       "min        -1.000000      -1.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         1.000000       0.000000       1.000000       1.000000   \n",
       "max         1.000000       6.000000       1.000000       1.000000   \n",
       "\n",
       "       ps_ind_08_bin  ps_ind_09_bin  ...     ps_calc_11     ps_calc_12  \\\n",
       "count  595212.000000  595212.000000  ...  595212.000000  595212.000000   \n",
       "mean        0.163921       0.185304  ...       5.441382       1.441918   \n",
       "std         0.370205       0.388544  ...       2.332871       1.202963   \n",
       "min         0.000000       0.000000  ...       0.000000       0.000000   \n",
       "25%         0.000000       0.000000  ...       4.000000       1.000000   \n",
       "50%         0.000000       0.000000  ...       5.000000       1.000000   \n",
       "75%         0.000000       0.000000  ...       7.000000       2.000000   \n",
       "max         1.000000       1.000000  ...      19.000000      10.000000   \n",
       "\n",
       "          ps_calc_13     ps_calc_14  ps_calc_15_bin  ps_calc_16_bin  \\\n",
       "count  595212.000000  595212.000000   595212.000000   595212.000000   \n",
       "mean        2.872288       7.539026        0.122427        0.627840   \n",
       "std         1.694887       2.746652        0.327779        0.483381   \n",
       "min         0.000000       0.000000        0.000000        0.000000   \n",
       "25%         2.000000       6.000000        0.000000        0.000000   \n",
       "50%         3.000000       7.000000        0.000000        1.000000   \n",
       "75%         4.000000       9.000000        0.000000        1.000000   \n",
       "max        13.000000      23.000000        1.000000        1.000000   \n",
       "\n",
       "       ps_calc_17_bin  ps_calc_18_bin  ps_calc_19_bin  ps_calc_20_bin  \n",
       "count   595212.000000   595212.000000   595212.000000   595212.000000  \n",
       "mean         0.554182        0.287182        0.349024        0.153318  \n",
       "std          0.497056        0.452447        0.476662        0.360295  \n",
       "min          0.000000        0.000000        0.000000        0.000000  \n",
       "25%          0.000000        0.000000        0.000000        0.000000  \n",
       "50%          1.000000        0.000000        0.000000        0.000000  \n",
       "75%          1.000000        1.000000        1.000000        0.000000  \n",
       "max          1.000000        1.000000        1.000000        1.000000  \n",
       "\n",
       "[8 rows x 58 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insurance_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's skip EDA for now. We'll use SGDClassifier and build a simple baseline: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html.\n",
    "Note that loss='log' gives logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = insurance_data['target']\n",
    "X = insurance_data.drop(columns=['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = [column for column in X if not (column.endswith(\"cat\") or column.endswith(\"bin\"))]\n",
    "numeric_transformer = Pipeline(steps=[('scaler', StandardScaler())])\n",
    "\n",
    "categorical_features = [column for column in X if (column.endswith(\"cat\") or column.endswith(\"bin\"))]\n",
    "categorical_transformer = Pipeline(steps=[('encoder', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                           ('classifier', SGDClassifier(loss='log', alpha=0.001, n_jobs=-1, random_state=14))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll calculate the model accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9635536838332475"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_true=y_valid, y_pred=clf.predict(X_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow! Our model gets ~0.963 accuracy! But is it really good?...\n",
    "\n",
    "Let's plot the confusion matrix and analyze the errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "disp = plot_confusion_matrix(clf, X_valid, y_valid,\n",
    "                             cmap=plt.cm.Blues,\n",
    "                             normalize=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, it turns out that our model is completely useless. Let's calculate some basic statistics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>ps_ind_01</th>\n",
       "      <th>ps_ind_02_cat</th>\n",
       "      <th>ps_ind_03</th>\n",
       "      <th>ps_ind_04_cat</th>\n",
       "      <th>ps_ind_05_cat</th>\n",
       "      <th>ps_ind_06_bin</th>\n",
       "      <th>ps_ind_07_bin</th>\n",
       "      <th>ps_ind_08_bin</th>\n",
       "      <th>ps_ind_09_bin</th>\n",
       "      <th>...</th>\n",
       "      <th>ps_calc_11</th>\n",
       "      <th>ps_calc_12</th>\n",
       "      <th>ps_calc_13</th>\n",
       "      <th>ps_calc_14</th>\n",
       "      <th>ps_calc_15_bin</th>\n",
       "      <th>ps_calc_16_bin</th>\n",
       "      <th>ps_calc_17_bin</th>\n",
       "      <th>ps_calc_18_bin</th>\n",
       "      <th>ps_calc_19_bin</th>\n",
       "      <th>ps_calc_20_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.036448</td>\n",
       "      <td>1.900378</td>\n",
       "      <td>1.358943</td>\n",
       "      <td>4.423318</td>\n",
       "      <td>0.416794</td>\n",
       "      <td>0.405188</td>\n",
       "      <td>0.393742</td>\n",
       "      <td>0.257033</td>\n",
       "      <td>0.163921</td>\n",
       "      <td>0.185304</td>\n",
       "      <td>...</td>\n",
       "      <td>5.441382</td>\n",
       "      <td>1.441918</td>\n",
       "      <td>2.872288</td>\n",
       "      <td>7.539026</td>\n",
       "      <td>0.122427</td>\n",
       "      <td>0.627840</td>\n",
       "      <td>0.554182</td>\n",
       "      <td>0.287182</td>\n",
       "      <td>0.349024</td>\n",
       "      <td>0.153318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.187401</td>\n",
       "      <td>1.983789</td>\n",
       "      <td>0.664594</td>\n",
       "      <td>2.699902</td>\n",
       "      <td>0.493311</td>\n",
       "      <td>1.350642</td>\n",
       "      <td>0.488579</td>\n",
       "      <td>0.436998</td>\n",
       "      <td>0.370205</td>\n",
       "      <td>0.388544</td>\n",
       "      <td>...</td>\n",
       "      <td>2.332871</td>\n",
       "      <td>1.202963</td>\n",
       "      <td>1.694887</td>\n",
       "      <td>2.746652</td>\n",
       "      <td>0.327779</td>\n",
       "      <td>0.483381</td>\n",
       "      <td>0.497056</td>\n",
       "      <td>0.452447</td>\n",
       "      <td>0.476662</td>\n",
       "      <td>0.360295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              target      ps_ind_01  ps_ind_02_cat      ps_ind_03  \\\n",
       "count  595212.000000  595212.000000  595212.000000  595212.000000   \n",
       "mean        0.036448       1.900378       1.358943       4.423318   \n",
       "std         0.187401       1.983789       0.664594       2.699902   \n",
       "min         0.000000       0.000000      -1.000000       0.000000   \n",
       "25%         0.000000       0.000000       1.000000       2.000000   \n",
       "50%         0.000000       1.000000       1.000000       4.000000   \n",
       "75%         0.000000       3.000000       2.000000       6.000000   \n",
       "max         1.000000       7.000000       4.000000      11.000000   \n",
       "\n",
       "       ps_ind_04_cat  ps_ind_05_cat  ps_ind_06_bin  ps_ind_07_bin  \\\n",
       "count  595212.000000  595212.000000  595212.000000  595212.000000   \n",
       "mean        0.416794       0.405188       0.393742       0.257033   \n",
       "std         0.493311       1.350642       0.488579       0.436998   \n",
       "min        -1.000000      -1.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         1.000000       0.000000       1.000000       1.000000   \n",
       "max         1.000000       6.000000       1.000000       1.000000   \n",
       "\n",
       "       ps_ind_08_bin  ps_ind_09_bin  ...     ps_calc_11     ps_calc_12  \\\n",
       "count  595212.000000  595212.000000  ...  595212.000000  595212.000000   \n",
       "mean        0.163921       0.185304  ...       5.441382       1.441918   \n",
       "std         0.370205       0.388544  ...       2.332871       1.202963   \n",
       "min         0.000000       0.000000  ...       0.000000       0.000000   \n",
       "25%         0.000000       0.000000  ...       4.000000       1.000000   \n",
       "50%         0.000000       0.000000  ...       5.000000       1.000000   \n",
       "75%         0.000000       0.000000  ...       7.000000       2.000000   \n",
       "max         1.000000       1.000000  ...      19.000000      10.000000   \n",
       "\n",
       "          ps_calc_13     ps_calc_14  ps_calc_15_bin  ps_calc_16_bin  \\\n",
       "count  595212.000000  595212.000000   595212.000000   595212.000000   \n",
       "mean        2.872288       7.539026        0.122427        0.627840   \n",
       "std         1.694887       2.746652        0.327779        0.483381   \n",
       "min         0.000000       0.000000        0.000000        0.000000   \n",
       "25%         2.000000       6.000000        0.000000        0.000000   \n",
       "50%         3.000000       7.000000        0.000000        1.000000   \n",
       "75%         4.000000       9.000000        0.000000        1.000000   \n",
       "max        13.000000      23.000000        1.000000        1.000000   \n",
       "\n",
       "       ps_calc_17_bin  ps_calc_18_bin  ps_calc_19_bin  ps_calc_20_bin  \n",
       "count   595212.000000   595212.000000   595212.000000   595212.000000  \n",
       "mean         0.554182        0.287182        0.349024        0.153318  \n",
       "std          0.497056        0.452447        0.476662        0.360295  \n",
       "min          0.000000        0.000000        0.000000        0.000000  \n",
       "25%          0.000000        0.000000        0.000000        0.000000  \n",
       "50%          1.000000        0.000000        0.000000        0.000000  \n",
       "75%          1.000000        1.000000        1.000000        0.000000  \n",
       "max          1.000000        1.000000        1.000000        1.000000  \n",
       "\n",
       "[8 rows x 58 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insurance_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you see, there are less than 4% of positive examples, so we have to deal with a highly imbalanced dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x='target', data=insurance_data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy is not informative here and the Normalized Gini Coefficient will be used instead: https://www.kaggle.com/c/porto-seguro-safe-driver-prediction/overview/evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for calculating Normalized gini coefficient\n",
    "# https://www.kaggle.com/c/ClaimPredictionChallenge/discussion/703\n",
    "def gini(actual, pred, cmpcol = 0, sortcol = 1):  \n",
    "    assert(len(actual) == len(pred))  \n",
    "    epsilon = 1e-7\n",
    "    values = np.asarray(np.c_[actual, pred, np.arange(len(actual))], dtype=np.float)  \n",
    "    values = values[np.lexsort((values[:, 2], -1 * values[:, 1]))]  \n",
    "    total = values[:, 0].sum() \n",
    "    gini_sum = (values[:, 0].cumsum().sum() + epsilon) / (total + epsilon)  \n",
    "  \n",
    "    gini_sum -= (len(actual) + 1) / 2  \n",
    "    return gini_sum / len(actual)  \n",
    "  \n",
    "def gini_normalized(a, p):  \n",
    "    '''Function to calculate the normalized gini coefficient'''\n",
    "    return gini(a, p) / gini(a, a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(1.5 points)** Prove that the **Normalized Gini Coefficient** is equivalent to **2 x AUC - 1** :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict_proba(X_valid)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gini:     0.2558723581569817\n",
      "2*AUC-1:  0.25587235816871434\n"
     ]
    }
   ],
   "source": [
    "print('gini:    ', gini_normalized(y_valid, y_pred))\n",
    "print('2*AUC-1: ',2*roc_auc_score(y_valid, y_pred)-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./data/gini.auc.png\" style=\"width:500px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Gini Coefficient is a direct conversion from AUC through a simple formula: Gini = (AUC x 2) -1. They measure exactly the same. And it is possible to go directly from one measure to the other, back and forth. The only reason to use Gini over AUC is the improvement in the scale’s interpretability: while the scale of a good predicting model AUC goes from 0.5 to 1, the scale in the case of Gini goes from 0 to 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(0.5 points)** By the way, what other metrics could you suggest for this problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are other ranking metrics that are less widely used, such as modification to the ROC Curve for imbalanced classification. And like the ROC AUC, we can calculate the area under the curve as a score and use that score to compare classifiers. In this case, the focus on the minority class makes the **PR AUC**(Precision-Recall AUC) more useful for imbalanced classification problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's calculate the Normalized Gini Coefficient:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict_proba(X_valid)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2558723581569817"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gini_normalized(y_valid, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(0.5 points + Y bonus points)** Try different approaches: oversampling / undersampling, careful feature analysis and feature engineering, etc., to get a reasonable pipeline and improve the model quality. Use cross-validation for model evaluation.\n",
    "\n",
    "Select the best model, load the test set and make the predictions. Submit them to kaggle.\n",
    "Y bonus points will be calculated as $\\frac{round(200 * \\max(score - 0.253, 0))}{2}$, where *score* is your kaggle leaderboard score.\n",
    "\n",
    "Note: do not use any classification models which have not been covered in the lessons yet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our data is highly imbalanced, we will perform a stratified split on our dataset. It will preserve the percentage of samples for our split. The predictions of an unstratified split will not preserve the original distribution of our target class. Therefore an imbalanced dataset should be split in a stratified manner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target             0.00\n",
       "ps_ind_01          0.00\n",
       "ps_ind_02_cat      0.04\n",
       "ps_ind_03          0.00\n",
       "ps_ind_04_cat      0.01\n",
       "ps_ind_05_cat      0.98\n",
       "ps_ind_06_bin      0.00\n",
       "ps_ind_07_bin      0.00\n",
       "ps_ind_08_bin      0.00\n",
       "ps_ind_09_bin      0.00\n",
       "ps_ind_10_bin      0.00\n",
       "ps_ind_11_bin      0.00\n",
       "ps_ind_12_bin      0.00\n",
       "ps_ind_13_bin      0.00\n",
       "ps_ind_14          0.00\n",
       "ps_ind_15          0.00\n",
       "ps_ind_16_bin      0.00\n",
       "ps_ind_17_bin      0.00\n",
       "ps_ind_18_bin      0.00\n",
       "ps_reg_01          0.00\n",
       "ps_reg_02          0.00\n",
       "ps_reg_03         18.11\n",
       "ps_car_01_cat      0.02\n",
       "ps_car_02_cat      0.00\n",
       "ps_car_03_cat     69.09\n",
       "ps_car_04_cat      0.00\n",
       "ps_car_05_cat     44.78\n",
       "ps_car_06_cat      0.00\n",
       "ps_car_07_cat      1.93\n",
       "ps_car_08_cat      0.00\n",
       "ps_car_09_cat      0.10\n",
       "ps_car_10_cat      0.00\n",
       "ps_car_11_cat      0.00\n",
       "ps_car_11          0.00\n",
       "ps_car_12          0.00\n",
       "ps_car_13          0.00\n",
       "ps_car_14          7.16\n",
       "ps_car_15          0.00\n",
       "ps_calc_01         0.00\n",
       "ps_calc_02         0.00\n",
       "ps_calc_03         0.00\n",
       "ps_calc_04         0.00\n",
       "ps_calc_05         0.00\n",
       "ps_calc_06         0.00\n",
       "ps_calc_07         0.00\n",
       "ps_calc_08         0.00\n",
       "ps_calc_09         0.00\n",
       "ps_calc_10         0.00\n",
       "ps_calc_11         0.00\n",
       "ps_calc_12         0.00\n",
       "ps_calc_13         0.00\n",
       "ps_calc_14         0.00\n",
       "ps_calc_15_bin     0.00\n",
       "ps_calc_16_bin     0.00\n",
       "ps_calc_17_bin     0.00\n",
       "ps_calc_18_bin     0.00\n",
       "ps_calc_19_bin     0.00\n",
       "ps_calc_20_bin     0.00\n",
       "dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#percentage of missing values\n",
    "(insurance_data == -1).mean().round(4)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = SGDClassifier(loss='log', penalty = 'l1', n_jobs=-1)\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "auc_lr = roc_auc_score(y_valid, lr.predict_proba(X_valid)[:,1])\n",
    "gini_lr = gini_normalized(y_valid, lr.predict_proba(X_valid)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gini: 0.2211177442311096\n",
      "AUC: 0.6105588721217652\n"
     ]
    }
   ],
   "source": [
    "print('Gini:', gini_lr)\n",
    "print('AUC:', auc_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = pd.read_csv(os.path.join(PATH, 'porto', 'test.csv')).set_index('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test_scaled = StandardScaler().fit_transform(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_id = data_test.index\n",
    "pred_test = lr.predict_proba(data_test_scaled)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame()\n",
    "submission['id'] = np.arange(data_test.shape[0])\n",
    "submission['target'] = pred_test\n",
    "submission.to_csv('my_submission.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv('my_submission.csv').set_index('id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./data/score.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "calculate Y bonus points,\n",
    "0.217*0.253 < 0 so I've deserved 0 additional points"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
